{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from slanggen import datatools\n",
    "from slanggen import models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 16:14:10.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslanggen.datatools\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mLoading processed words from ../assets/straattaal.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "processed_words = datatools.load_data(Path(\"../assets/straattaal.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = models.buildBPE(corpus=processed_words, vocab_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on',\n",
       " 'ge',\n",
       " '</s>',\n",
       " 'h',\n",
       " 'i',\n",
       " 't',\n",
       " 'ff',\n",
       " 'v',\n",
       " 'q',\n",
       " 'ek',\n",
       " 'bo',\n",
       " '<pad>',\n",
       " '!',\n",
       " 'je',\n",
       " 'la',\n",
       " 'Ã',\n",
       " 'be',\n",
       " 'rie',\n",
       " 'ra',\n",
       " 'ta',\n",
       " 'am',\n",
       " 'u',\n",
       " 'me',\n",
       " 'ma',\n",
       " 'chi',\n",
       " '7',\n",
       " 'ko',\n",
       " 'k',\n",
       " 'ak',\n",
       " 'Ġ',\n",
       " 'ch',\n",
       " 'm',\n",
       " 'w',\n",
       " 'z',\n",
       " '<s>',\n",
       " 'sh',\n",
       " 'd',\n",
       " '!</',\n",
       " 'at',\n",
       " 'ne',\n",
       " 'c',\n",
       " 'ga',\n",
       " 'gga',\n",
       " 'kie',\n",
       " 'se',\n",
       " 'ª',\n",
       " 'ka',\n",
       " 'pa',\n",
       " 'sc',\n",
       " 'ba',\n",
       " 'en',\n",
       " 'ss',\n",
       " 'oe',\n",
       " 's',\n",
       " '</',\n",
       " 'el',\n",
       " 'ro',\n",
       " 'lla',\n",
       " 'li',\n",
       " 'an',\n",
       " 'o',\n",
       " 'r',\n",
       " '>',\n",
       " 'j',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'g',\n",
       " 'x',\n",
       " 'er',\n",
       " 'e',\n",
       " '/',\n",
       " 'ke',\n",
       " 'pp',\n",
       " 'na',\n",
       " 'bi',\n",
       " 'ki',\n",
       " 'koe',\n",
       " 'ti',\n",
       " 'ie',\n",
       " 'et',\n",
       " 'ri',\n",
       " 'y',\n",
       " 'll',\n",
       " '?',\n",
       " 'b',\n",
       " 'wi',\n",
       " \"'\",\n",
       " '9',\n",
       " 'l',\n",
       " 'ken',\n",
       " '<mask>',\n",
       " '3',\n",
       " 'p',\n",
       " 'f',\n",
       " 'wa',\n",
       " '-',\n",
       " 'to',\n",
       " '<unk>',\n",
       " '<']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wa', 'g', 'g', 'ie']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer.encode(\"waggie\")\n",
    "enc.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waggie'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(enc.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 16, 44,  ...,  0,  0,  0],\n",
       "        [ 1, 21, 16,  ...,  0,  0,  0],\n",
       "        [ 1, 21, 51,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1, 27, 36,  ...,  0,  0,  0],\n",
       "        [ 1, 23, 20,  ...,  0,  0,  0],\n",
       "        [ 1, 37, 16,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences = datatools.preprocess(processed_words, tokenizer)\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShiftedDataset torch.Size([453, 22])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datatools.ShiftedDataset(padded_sequences)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 22]), torch.Size([16, 22]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([5, 22]) torch.Size([5, 22])\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the vocab size based on the tokenizer\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "# Hyperparameters\n",
    "config = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_dim\": vocab_size,\n",
    "}\n",
    "\n",
    "model = models.SlangRNN(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22]), torch.Size([22]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 22]), torch.Size([16, 22]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50, min_lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 16:14:14.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [10/1000], Loss: 24.7057\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:14.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.1]\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:15.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [20/1000], Loss: 22.7468\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:16.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [30/1000], Loss: 21.5703\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:16.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [40/1000], Loss: 20.5458\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:17.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [50/1000], Loss: 19.8953\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:18.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [60/1000], Loss: 19.4602\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:18.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [70/1000], Loss: 19.1058\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:19.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [80/1000], Loss: 19.0483\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:20.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [90/1000], Loss: 19.0969\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:20.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [100/1000], Loss: 18.6996\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:21.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [110/1000], Loss: 18.6726\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:22.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [120/1000], Loss: 18.5305\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:22.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [130/1000], Loss: 18.4690\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:23.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [140/1000], Loss: 18.8257\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:24.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [150/1000], Loss: 18.5193\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:25.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [160/1000], Loss: 18.4797\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:25.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [170/1000], Loss: 18.2343\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:26.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [180/1000], Loss: 17.7977\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:27.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [190/1000], Loss: 17.8803\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:27.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [200/1000], Loss: 17.9032\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:28.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [210/1000], Loss: 17.5477\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:29.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [220/1000], Loss: 17.3796\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:30.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [230/1000], Loss: 17.2817\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:30.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [240/1000], Loss: 17.2651\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:31.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [250/1000], Loss: 17.1870\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:32.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [260/1000], Loss: 17.0904\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:32.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [270/1000], Loss: 16.9608\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:33.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [280/1000], Loss: 17.1019\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:34.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [290/1000], Loss: 17.1103\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:35.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [300/1000], Loss: 17.0176\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:35.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [310/1000], Loss: 16.8202\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:36.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [320/1000], Loss: 17.0498\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:37.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [330/1000], Loss: 16.7867\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:37.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [340/1000], Loss: 17.0051\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:38.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [350/1000], Loss: 17.3174\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:39.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [360/1000], Loss: 17.1773\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:40.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [370/1000], Loss: 16.8981\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:40.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [380/1000], Loss: 16.8948\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:40.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.010000000000000002]\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:41.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [390/1000], Loss: 16.6708\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:42.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [400/1000], Loss: 16.8733\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:42.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [410/1000], Loss: 16.9371\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:43.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [420/1000], Loss: 16.8571\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:44.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [430/1000], Loss: 16.6011\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:44.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [440/1000], Loss: 16.6584\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:45.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [450/1000], Loss: 16.3009\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:46.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [460/1000], Loss: 16.3691\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:46.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [470/1000], Loss: 16.6881\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:47.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [480/1000], Loss: 16.3049\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:48.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [490/1000], Loss: 16.3686\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:48.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [500/1000], Loss: 16.3032\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:49.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [510/1000], Loss: 16.1888\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:50.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [520/1000], Loss: 16.1397\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:50.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [530/1000], Loss: 16.2063\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:51.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [540/1000], Loss: 16.2228\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:52.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [550/1000], Loss: 16.5781\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:53.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [560/1000], Loss: 16.5906\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:53.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [570/1000], Loss: 16.4737\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:54.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [580/1000], Loss: 16.4203\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:55.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [590/1000], Loss: 16.4514\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:55.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.0010000000000000002]\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:55.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [600/1000], Loss: 16.5376\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:56.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [610/1000], Loss: 16.4520\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:57.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [620/1000], Loss: 16.3350\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:57.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [630/1000], Loss: 16.2619\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:58.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [640/1000], Loss: 16.1763\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:58.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.00010000000000000003]\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:59.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [650/1000], Loss: 16.1563\u001b[0m\n",
      "\u001b[32m2024-06-20 16:14:59.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [660/1000], Loss: 16.3657\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:00.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [670/1000], Loss: 16.2004\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:01.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [680/1000], Loss: 16.0584\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:01.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [690/1000], Loss: 15.9635\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:02.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [700/1000], Loss: 15.9243\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:03.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [710/1000], Loss: 16.0158\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:04.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [720/1000], Loss: 15.9291\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:04.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [730/1000], Loss: 16.0335\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:05.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [740/1000], Loss: 16.2208\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:06.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [750/1000], Loss: 16.1466\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:06.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [760/1000], Loss: 16.7940\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:07.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [770/1000], Loss: 16.0018\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:08.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [780/1000], Loss: 16.1478\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:08.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [790/1000], Loss: 16.2308\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:09.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [800/1000], Loss: 16.2853\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:10.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [810/1000], Loss: 16.2341\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:10.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [820/1000], Loss: 16.6807\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:11.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [830/1000], Loss: 16.3228\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:12.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [840/1000], Loss: 16.8145\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:12.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [850/1000], Loss: 16.7528\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:13.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [860/1000], Loss: 16.2435\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [870/1000], Loss: 16.1744\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:14.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [880/1000], Loss: 16.4613\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:15.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [890/1000], Loss: 16.9572\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:16.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [900/1000], Loss: 16.3368\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:16.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [910/1000], Loss: 16.2113\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:17.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [920/1000], Loss: 16.6355\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:18.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [930/1000], Loss: 16.6112\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:19.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [940/1000], Loss: 16.5917\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:20.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [950/1000], Loss: 16.4890\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:20.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [960/1000], Loss: 16.5401\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:21.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [970/1000], Loss: 16.3202\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:22.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [980/1000], Loss: 16.1530\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:23.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [990/1000], Loss: 16.2284\u001b[0m\n",
      "\u001b[32m2024-06-20 16:15:23.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [1000/1000], Loss: 16.1576\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import torch\n",
    "\n",
    "epochs = 800\n",
    "history = []\n",
    "last_lr = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.init_hidden(x)\n",
    "        # input_seq, target_seq = dataset[i]\n",
    "\n",
    "        output, hidden = model(x, hidden)\n",
    "\n",
    "        loss += loss_fn(output.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    history.append(loss.item())\n",
    "    curr_lr = scheduler.get_last_lr()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        logger.info(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "        if last_lr != curr_lr:\n",
    "            last_lr = curr_lr\n",
    "            logger.info(f\"Current learning rate: {curr_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000006e-12]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../artefacts/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.SlangRNN(config)\n",
    "model.load_state_dict(torch.load(\"../artefacts/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_letter = 'a'\n",
    "start_token_idx = tokenizer.encode(\"<s>\").ids[0]\n",
    "start_letter_idx = tokenizer.encode(start_letter).ids[0]\n",
    "input_seq = torch.tensor([[start_token_idx, start_letter_idx]], dtype=torch.long)\n",
    "\n",
    "generated_word = [start_letter_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_letter = 'a'\n",
    "max_length = 20\n",
    "temperature = 1.0\n",
    "start_token_idx = tokenizer.encode(\"<s>\").ids[0]\n",
    "start_letter_idx = tokenizer.encode(start_letter).ids[0]\n",
    "input_seq = torch.tensor([[start_token_idx, start_letter_idx]], dtype=torch.long)\n",
    "\n",
    "generated_word = [start_letter_idx]\n",
    "hidden = model.init_hidden(input_seq)\n",
    "for _ in range(max_length - 1):\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "    output = output.squeeze(0)\n",
    "    output = output[-1, :].view(-1).div(temperature).exp()\n",
    "    next_token = torch.multinomial(output, 1).item()\n",
    "    if next_token == tokenizer.token_to_id(\"<pad>\"):\n",
    "        break\n",
    "    generated_word.append(next_token)\n",
    "    input_seq = torch.tensor([generated_word], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appet'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden(input_seq)\n",
    "output, hidden = model(input_seq, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 100]), torch.Size([2, 1, 64]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gu', 'bakts', 'vu', 'rui', 'otybolla', 'ski', 'ai']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sample_n(processed_words, n=10, model=model, tokenizer=tokenizer, max_length=20, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"../artefacts/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../artefacts/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'assets_dir': 'assets',\n",
       "  'artefacts_dir': 'artefacts',\n",
       "  'filename': 'straattaal.txt'},\n",
       " 'model': {'embedding_dim': 64, 'hidden_dim': 64, 'num_layers': 2},\n",
       " 'training': {'epochs': 500, 'learning_rate': 0.01}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../artefacts/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
