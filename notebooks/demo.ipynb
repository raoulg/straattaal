{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from slanggen import datatools\n",
    "from slanggen import models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scraped the \"Amsterdamse straattaal woordenboek\" , see [link](https://www.mijnwoordenboek.nl/dialect/Amsterdamse%20straattaal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 16:28:16,315 | main - INFO - Loading processed words from ../assets/straattaal.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['<s>a mooi?</s>',\n",
       "  '<s>fawaka?</s>',\n",
       "  '<s>faka?</s>',\n",
       "  '<s>inshallah</s>',\n",
       "  '<s>fok op</s>',\n",
       "  '<s>mahlish</s>',\n",
       "  '<s>fakka</s>',\n",
       "  '<s>het is planga weer</s>',\n",
       "  '<s>kifesh</s>',\n",
       "  '<s>faka</s>'],\n",
       " 453)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_words = datatools.load_data(Path(\"../assets/straattaal.txt\"))\n",
    "processed_words[:10], len(processed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 453 words in total. I added a start `<s>` and stop `</s>` tag.\n",
    "We will use a Byte Pair Encoding (BPE) algorithm to learn the subword units from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'\", 's', '<unk>', 'x', '/', 'Ä ', 'je', 'e', 'wa', 'w']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = models.buildBPE(corpus=processed_words, vocab_size=100)\n",
    "list(tokenizer.get_vocab())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now encode a word and see which tokens are created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wa', 'g', 'g', 'ie']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer.encode(\"waggie\")\n",
    "enc.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reconstruct the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waggie'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(enc.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the sequences. We will:\n",
    "- transform words into subtokens, and then into arbitrary integers\n",
    "- add zeros to make all sequences the same length (padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 16, 44,  ...,  0,  0,  0],\n",
       "        [ 1, 21, 16,  ...,  0,  0,  0],\n",
       "        [ 1, 21, 51,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1, 27, 36,  ...,  0,  0,  0],\n",
       "        [ 1, 23, 20,  ...,  0,  0,  0],\n",
       "        [ 1, 37, 16,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences = datatools.preprocess(processed_words, tokenizer)\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every word now is a list of integers. We will shift the sequence one position, such that the target (to predict) is the next token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShiftedDataset torch.Size([453, 22])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datatools.ShiftedDataset(padded_sequences)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([ 1, 16, 44, 28, 30, 30, 24, 15,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0])\n",
      "output: tensor([16, 44, 28, 30, 30, 24, 15,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "print(f\"input: {x}\")\n",
    "print(f\"output: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a Dataloader. This will batch the sequences and shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 22]), torch.Size([16, 22]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([16, 22]) torch.Size([16, 22])\n",
      "torch.Size([5, 22]) torch.Size([5, 22])\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will use the vocabulary size to use as an output size for the model.\n",
    "The model now takes:\n",
    "- as input: a sequence of integers\n",
    "- as output: for every possible BPE token, the probability that it is the next token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the vocab size based on the tokenizer\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set up all the ingredients:\n",
    "- the model uses 64 dimensions to represent the language\n",
    "- we can calculate the loss (the difference between the actual next token and the predicted next token)\n",
    "- the optimizer will tell the model in which direction to adjust the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "from torch import nn, optim\n",
    "# Hyperparameters\n",
    "config = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_dim\": vocab_size,\n",
    "}\n",
    "\n",
    "model = models.SlangRNN(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50, min_lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train for 800 epochs. This means we will present the full dataset of 453 words for 800 times to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 16:39:27.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [10/800], Loss: 24.9769\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:27.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.1]\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:28.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [20/800], Loss: 22.4989\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:29.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [30/800], Loss: 21.2633\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:29.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [40/800], Loss: 20.2699\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:30.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [50/800], Loss: 19.6305\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:31.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [60/800], Loss: 19.2329\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:32.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [70/800], Loss: 18.9792\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:32.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [80/800], Loss: 19.1678\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:33.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [90/800], Loss: 18.5646\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:34.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [100/800], Loss: 18.5987\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:35.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [110/800], Loss: 18.2792\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:35.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [120/800], Loss: 18.3215\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:36.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [130/800], Loss: 18.4002\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:37.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [140/800], Loss: 17.7065\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:38.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [150/800], Loss: 17.8049\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:38.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [160/800], Loss: 18.1591\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:39.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [170/800], Loss: 17.6284\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:40.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [180/800], Loss: 17.7434\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:41.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [190/800], Loss: 18.2609\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:41.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [200/800], Loss: 17.5699\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:42.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [210/800], Loss: 17.5704\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:43.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [220/800], Loss: 17.4739\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:44.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [230/800], Loss: 17.2862\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:44.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [240/800], Loss: 17.2446\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:45.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [250/800], Loss: 17.2570\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:46.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [260/800], Loss: 17.6478\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:47.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [270/800], Loss: 17.7527\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:47.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [280/800], Loss: 17.6512\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:48.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [290/800], Loss: 17.4349\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:49.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [300/800], Loss: 17.4953\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:50.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [310/800], Loss: 17.0097\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:50.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mCurrent learning rate: [0.010000000000000002]\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:51.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [320/800], Loss: 16.8559\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:51.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [330/800], Loss: 16.7446\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:52.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [340/800], Loss: 16.8688\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:53.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [350/800], Loss: 16.5493\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:54.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [360/800], Loss: 16.5337\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:54.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [370/800], Loss: 16.5090\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:55.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [380/800], Loss: 16.4938\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:56.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [390/800], Loss: 16.3801\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:57.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [400/800], Loss: 16.3880\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:57.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [410/800], Loss: 16.4230\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:58.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [420/800], Loss: 16.4113\u001b[0m\n",
      "\u001b[32m2024-10-10 16:39:59.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [430/800], Loss: 16.2451\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:00.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [440/800], Loss: 16.2085\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:00.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [450/800], Loss: 16.0923\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:01.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [460/800], Loss: 16.2115\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:02.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [470/800], Loss: 16.1052\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:03.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [480/800], Loss: 16.0859\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:03.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [490/800], Loss: 16.0068\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:04.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [500/800], Loss: 15.9500\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:05.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [510/800], Loss: 15.9181\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:06.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [520/800], Loss: 15.8726\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:07.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [530/800], Loss: 15.8413\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:07.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [540/800], Loss: 15.8826\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:08.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [550/800], Loss: 15.7618\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:09.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [560/800], Loss: 15.7357\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:10.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [570/800], Loss: 15.6475\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [580/800], Loss: 15.6208\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:11.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [590/800], Loss: 15.5430\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:12.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [600/800], Loss: 15.7001\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:13.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [610/800], Loss: 15.5348\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:14.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [620/800], Loss: 15.4567\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:14.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [630/800], Loss: 15.3730\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:15.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [640/800], Loss: 15.3190\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:16.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [650/800], Loss: 15.3830\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:17.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [660/800], Loss: 15.2010\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:17.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [670/800], Loss: 15.2111\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:18.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [680/800], Loss: 15.1863\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:19.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [690/800], Loss: 15.2490\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:20.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [700/800], Loss: 15.1352\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:21.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [710/800], Loss: 15.1788\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:22.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [720/800], Loss: 15.1444\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:23.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [730/800], Loss: 15.2143\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:23.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [740/800], Loss: 14.9030\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:24.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [750/800], Loss: 14.9972\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:25.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [760/800], Loss: 14.9426\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:26.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [770/800], Loss: 15.1980\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:26.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [780/800], Loss: 15.0484\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:27.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [790/800], Loss: 14.9688\u001b[0m\n",
      "\u001b[32m2024-10-10 16:40:28.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch [800/800], Loss: 14.9513\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import torch\n",
    "\n",
    "epochs = 800\n",
    "history = []\n",
    "last_lr = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.init_hidden(x)\n",
    "        # input_seq, target_seq = dataset[i]\n",
    "\n",
    "        output, hidden = model(x, hidden)\n",
    "\n",
    "        loss += loss_fn(output.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    history.append(loss.item())\n",
    "    curr_lr = scheduler.get_last_lr()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        logger.info(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "        if last_lr != curr_lr:\n",
    "            last_lr = curr_lr\n",
    "            logger.info(f\"Current learning rate: {curr_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 40.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim(0, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save, and load, the trained model for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../artefacts/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.SlangRNN(config)\n",
    "model.load_state_dict(torch.load(\"../artefacts/model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now give a starting letter, eg 'a', and give the model a sequence of start_token and start_letter.\n",
    "The model will now start to predict next tokens, until it predicts the stop_token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_letter = 'a'\n",
    "max_length = 20\n",
    "temperature = 1.0\n",
    "start_token_idx = tokenizer.encode(\"<s>\").ids[0]\n",
    "start_letter_idx = tokenizer.encode(start_letter).ids[0]\n",
    "input_seq = torch.tensor([[start_token_idx, start_letter_idx]], dtype=torch.long)\n",
    "\n",
    "generated_word = [start_letter_idx]\n",
    "hidden = model.init_hidden(input_seq)\n",
    "for _ in range(max_length - 1):\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "    output = output.squeeze(0)\n",
    "    output = output[-1, :].view(-1).div(temperature).exp()\n",
    "    next_token = torch.multinomial(output, 1).item()\n",
    "    if next_token == tokenizer.token_to_id(\"<pad>\"):\n",
    "        break\n",
    "    generated_word.append(next_token)\n",
    "    input_seq = torch.tensor([generated_word], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 24, 22, 23, 35, 46, 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can decode into a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aighten'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop this process to generate multiple words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'krum',\n",
       " 'uu',\n",
       " 'we7nes',\n",
       " 'zai',\n",
       " \"o'toe\",\n",
       " 'don',\n",
       " 'ey',\n",
       " 'ulangen-ven',\n",
       " 'ummaal boers']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sample_n(processed_words, n=10, model=model, tokenizer=tokenizer, max_length=20, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save everything for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"../artefacts/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../artefacts/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
